[{"path":"index.html","id":"workshop-simulating-power-for-mixed-effects-models","chapter":"Workshop: Simulating power for mixed-effects models","heading":"Workshop: Simulating power for mixed-effects models","text":"Dale J. BarrAMLaP Asia, November 30, 2023","code":""},{"path":"index.html","id":"background","chapter":"Workshop: Simulating power for mixed-effects models","heading":"Background","text":"Materials practical one-day workshop aimed conference attendees interested utilizing linear mixed-effects models research. Led Dr. Dale Barr University Glasgow, workshop provides introduction simulating power linear mixed-effects models.Two pre-requisites workshop : (1) basic understanding linear regression (2) familiarity R statistical programming environment (https://cran.r-project.org). Please R RStudio installed laptop prior start workshop, including packages tidyverse lme4.","code":""},{"path":"index.html","id":"workshop-plan","chapter":"Workshop: Simulating power for mixed-effects models","heading":"Workshop plan","text":"Part 1 (9:00-12:00): Building blocks simulation\nProvides overview critical programming skills Monte Carlo simulation. build skills writing script power simulation one-sample t-test.Part 1 (9:00-12:00): Building blocks simulationProvides overview critical programming skills Monte Carlo simulation. build skills writing script power simulation one-sample t-test.Part 2 (14:00-17:00): Simulating power linear mixed-effects models\nConceptual introduction data generating process (DGP) behind many models psycholinguistics, instructions adapt script generated Part 1 mixed-model context.Part 2 (14:00-17:00): Simulating power linear mixed-effects modelsConceptual introduction data generating process (DGP) behind many models psycholinguistics, instructions adapt script generated Part 1 mixed-model context.","code":""},{"path":"index.html","id":"notes-on-these-materials","chapter":"Workshop: Simulating power for mixed-effects models","heading":"Notes on these materials","text":"materials comprise interactive textbook. \"chapter\" contains embedded exercises well web applications help participants better understand content. interactive content work access material web browser. Printing material recommended.good keep local copy materials case website eventually disappears. can download offline version materials. contains current snapshot. things likely change workshop ongoing, best wait end workshop downloading permanent version.downloaded archive, just extract files, locate file index.html docs directory, open file using web browser.free re-use modify material textbook purposes, stipulation cite original work. Please note additional terms Creative Commons CC--SA 4.0 license governing re-use material.Barr, Dale J. (2023). Simulating power mixed-effects models (workshop materials). Downloaded https://dalejbarr.github.io/aa-powersim.book built using R bookdown package. source files available github.","code":""},{"path":"index.html","id":"found-an-issue","chapter":"Workshop: Simulating power for mixed-effects models","heading":"Found an issue?","text":"find errors typos, questions suggestions, please file issue https://github.com/dalejbarr/aa-powersim/issues. Thanks!","code":""},{"path":"building-blocks-of-simulation.html","id":"building-blocks-of-simulation","chapter":"1 Building blocks of simulation","heading":"1 Building blocks of simulation","text":"","code":""},{"path":"building-blocks-of-simulation.html","id":"coding-preliminaries","chapter":"1 Building blocks of simulation","heading":"1.1 Coding preliminaries","text":"main thing using R analyzing data, likely exposed many features R tidyverse needed data simulation, including random number generation (1.1.2), writing custom functions (1.1.6), iteration (1.1.3), nested tables (1.1.4.2), handling warnings messages (1.2.2.1), extracting statistics model objects (1.2.3).start providing basic overview topics task generating R script performs power simulation one-sample t-test various effect sample sizes. Although analytical solutions computing power type test, worth learning general principles dealing complexities linear mixed-effects models.follows, assume familiar \"pipes\" work R (either base pipe, |> dplyr pipe, %>%) following one-table verbs dplyr: select(), mutate(), summarize().","code":""},{"path":"building-blocks-of-simulation.html","id":"setting-up-the-environment","chapter":"1 Building blocks of simulation","heading":"1.1.1 Setting up the environment","text":"developing R script, good practice load packages need top script.wrapped calls suppressPackageStartupMessages() get messages come packages loaded time run script. just using tidyverse functions anyway, problems.","code":"\nsuppressPackageStartupMessages({\n  library(\"dplyr\")  # select(), mutate(), summarize(), inner_join()\n  library(\"tibble\") # tibble() [data entry]\n  library(\"purrr\")  # just for map()\n  library(\"tidyr\")  # nest(), unnest()\n\n  requireNamespace(\"broom\") # don't load, just fail if it's not there\n})"},{"path":"building-blocks-of-simulation.html","id":"rng","chapter":"1 Building blocks of simulation","heading":"1.1.2 Random number generation","text":"Simulating data means simulating random processes. Usually random process trying mimic sampling, .e., drawing (presumably random) sample population.involves randomly generating numbers kind statistical distribution. many purposes use univariate normal distribution via function rnorm(), included base R. want simulate data multivariate normal distribution (next section), can use MASS::mvrnorm().key arguments rnorm() :TASK: simulate 10 observations normal distribution mean 0 standard deviation 5.rnorm(10, sd = 5)Functions like rnorm() give random output based state internal random number generator (RNG). want get deterministic output, can \"seed\" random number generator using set.seed(). (Often makes sense , top script.) function set.seed() takes single argument, arbitrary integer value provides 'starting point'.TASK: set seed 1451 simulate 15 observations normal distribution mean 600 standard deviation 80. right, output EXACTLY match output .","code":"##  [1] 383.2186 522.1162 503.1198 640.4056 628.0002 759.7153 595.5522 516.1018\n##  [9] 479.3662 587.9051 775.4601 684.2209 671.1479 597.2221 618.4092\nset.seed(1451)\n\nrnorm(15, mean = 600, sd = 80)"},{"path":"building-blocks-of-simulation.html","id":"iterate","chapter":"1 Building blocks of simulation","heading":"1.1.3 Iterating using purrr::map()","text":"estimate power using simulation, need create function run many times—maybe 1,000 10,000 times get reliable estimate. course, going type function call many times; tedious, besides, might make mistakes. need something iteration us, possible changing input function time.many programming languages, accomplished writing \"\" loop. possible R well, going different way saves typing.going use function purrr::map(). look example. Suppose vector integers, x, wanted compute logarithm (log()) one. know map(), might type following.lot typing. map(), can just type .Note output comes form list. wanted output vector doubles, use map_dbl() instead.Now, default, log() gives natural logarithm (using base \\(e\\), Euler's number). want change base? pass additional argument base = 2 log within map. add like soBut makes syntax unclear: base = 2 argument map_dbl(), log()? Technically, argument map passed along log(), confusing. makes things needlessly hard debug. recommended way call log() within map() part anonymous function.allows us call log() \"normal\" way (.e., way typing console. \\(.x) says R \"pass along value x currently working function right hand side, giving new value .x\". Also, making explicit passing value map() function wish repeat makes easy work situations varying value first argument function.multiple arguments need pass function, can using purrr::pmap(), whose first argument takes list function arguments.deep dive topic iteration, see https://TODO.TASK: Write call map_dbl() calculates log 3 bases varying 2 7.","code":"\nx <- c(1L, 4L, 7L, 9L, 14L) # the 'L' after each number means \"long integer\"\n\nlog(x[1])\nlog(x[2])\nlog(x[3])\nlog(x[4])\nlog(x[5])## [1] 0\n## [1] 1.386294\n## [1] 1.94591\n## [1] 2.197225\n## [1] 2.639057\nmap(x, log)## [[1]]\n## [1] 0\n## \n## [[2]]\n## [1] 1.386294\n## \n## [[3]]\n## [1] 1.94591\n## \n## [[4]]\n## [1] 2.197225\n## \n## [[5]]\n## [1] 2.639057\nmap_dbl(x, log)## [1] 0.000000 1.386294 1.945910 2.197225 2.639057\nmap_dbl(x, log, base = 2)## [1] 0.000000 2.000000 2.807355 3.169925 3.807355\nmap_dbl(x, \\(.x) log(.x, base = 2))## [1] 0.000000 2.000000 2.807355 3.169925 3.807355\nmap_dbl(2:7, \\(.x) log(3, base = .x))## [1] 1.5849625 1.0000000 0.7924813 0.6826062 0.6131472 0.5645750"},{"path":"building-blocks-of-simulation.html","id":"creating-tibbles","chapter":"1 Building blocks of simulation","heading":"1.1.4 Creating \"tibbles\"","text":"Much involve working datasets stored tables, tabular data (R, table also called data.frame). analyzing data, usually create tables importing data file (e.g., CSV Excel file experiment data).simulating data, need create tables . tibble package functions help make easier. current purposes, really function need package tibble::tibble(), enhanced version base R data.frame() manual data entry.assume creating information participants study. participant given unique id recorded information age. can enter tibble() like .","code":"\nparticipants <- tibble(id = c(1L, 2L, 3L, 4L, 5L),\n                       age = c(27L, 18L, 43L, 72L, 21L))\n\nparticipants## # A tibble: 5 × 2\n##      id   age\n##   <int> <int>\n## 1     1    27\n## 2     2    18\n## 3     3    43\n## 4     4    72\n## 5     5    21"},{"path":"building-blocks-of-simulation.html","id":"save-typing-with-rep-seq-and-seq_len","chapter":"1 Building blocks of simulation","heading":"1.1.4.1 Save typing with rep(), seq(), and seq_len()","text":"now say going run participants Stroop interference task see color words printed congruent incongruent colors (e.g., word \"RED\" printed red font green font) name color font. assume person gets word twice, congruent condition incongruent condition. Now want make table six colors condition. resulting table look like .type manually tedious prone typos. Fortunately R function rep() allows us repeat values. Study code . understand works.TASK: Write code recreate Stroop stimuli table shown using rep() define column values. Name resulting table stimuli.Two functions useful simulation seq_len() seq(). e using later. Examples .","code":"## # A tibble: 12 × 2\n##    word   cond       \n##    <chr>  <chr>      \n##  1 red    congruent  \n##  2 red    incongruent\n##  3 green  congruent  \n##  4 green  incongruent\n##  5 blue   congruent  \n##  6 blue   incongruent\n##  7 yellow congruent  \n##  8 yellow incongruent\n##  9 purple congruent  \n## 10 purple incongruent\n## 11 orange congruent  \n## 12 orange incongruent\nrep(1:4, each = 3)##  [1] 1 1 1 2 2 2 3 3 3 4 4 4\nrep(5:7, times = 4)##  [1] 5 6 7 5 6 7 5 6 7 5 6 7\nrep(8:10, c(2, 3, 0))## [1] 8 8 9 9 9\nstimuli <- tibble(word = rep(c(\"red\", \"green\", \"blue\", \"yellow\",\n                               \"purple\", \"orange\"), each = 2),\n                  cond = rep(c(\"congruent\", \"incongruent\"), times = 6))\n## sequence of integers 1:length.out;\n## if length.out == 0 then 'empty'\nseq_len(length.out = 4)## [1] 1 2 3 4\nseq(from = 2, to = 7, by = .5)##  [1] 2.0 2.5 3.0 3.5 4.0 4.5 5.0 5.5 6.0 6.5 7.0\nseq(from = 2, to = 7, length.out = 5)## [1] 2.00 3.25 4.50 5.75 7.00"},{"path":"building-blocks-of-simulation.html","id":"nesting","chapter":"1 Building blocks of simulation","heading":"1.1.4.2 Nested tibbles","text":"Tibbles, like data.frame class derived, just specialized list structures. Lists useful data structures unlike vectors, element can different data type (character, integer, double, factor). data frames, however, essential list element length (number elements).great feature tibbles differs data.frame objects can columns whose values ... tibbles. , can tibbles inside tibbles, define columns using list() function.wanted \"expand\" nested tables can using tidyr::unnest().wanted , can reverse operation.useful? Well, mostly elegantly allows us account multilevel structure data, trials nested within participants. see shortly can combine map() (returns list) make columns whose elements tibbles simulated data, analyses performed tibbles.","code":"\n## just basic tibbles\nbeatles <- tibble(name = c(\"John\", \"Paul\", \"Ringo\", \"George\"),\n                  instrument = c(\"guitar\", \"bass\", \"drums\", \"guitar\"))\n\nrolling_stones <- tibble(name = c(\"Keith\", \"Mick\", \"Charlie\", \"Bill\"),\n                         instrument = c(\"guitar\", \"vocals\", \"drums\", \"bass\"))\n\n## a tibble with tibbles as elements\nboomer_bands <- tibble(band_name = c(\"Beatles\", \"Rolling Stones\"),\n                       band_members = list(beatles, rolling_stones))\n\nboomer_bands## # A tibble: 2 × 2\n##   band_name      band_members    \n##   <chr>          <list>          \n## 1 Beatles        <tibble [4 × 2]>\n## 2 Rolling Stones <tibble [4 × 2]>\nbb2 <- boomer_bands |>\n  unnest(band_members)\n\nbb2## # A tibble: 8 × 3\n##   band_name      name    instrument\n##   <chr>          <chr>   <chr>     \n## 1 Beatles        John    guitar    \n## 2 Beatles        Paul    bass      \n## 3 Beatles        Ringo   drums     \n## 4 Beatles        George  guitar    \n## 5 Rolling Stones Keith   guitar    \n## 6 Rolling Stones Mick    vocals    \n## 7 Rolling Stones Charlie drums     \n## 8 Rolling Stones Bill    bass\nbb2 |>\n  nest(band_members = c(name, instrument))## # A tibble: 2 × 2\n##   band_name      band_members    \n##   <chr>          <list>          \n## 1 Beatles        <tibble [4 × 2]>\n## 2 Rolling Stones <tibble [4 × 2]>"},{"path":"building-blocks-of-simulation.html","id":"combining-tibbles","chapter":"1 Building blocks of simulation","heading":"1.1.5 Combining tibbles","text":"Often end data scattered across different tables need merge single table. tidyverse provides powerful efficient functions merging data.","code":""},{"path":"building-blocks-of-simulation.html","id":"cartesian-join-with-dplyrcross_join","chapter":"1 Building blocks of simulation","heading":"1.1.5.1 Cartesian join with dplyr::cross_join()","text":"Occasionally want combine possible combinations rows across two tables, known \"Cartesian join.\" , can use function dplyr::cross_join(). easiest explain example.TASK: , created table participants stimuli. Combine two tables create table trials creates possible trials experiment participant sees stimulus . resulting table 60 rows. combining tables, remove column named age participants.","code":"\nsome_letters <- tibble(letter = c(\"A\", \"B\", \"C\"))\n\nsome_numbers <- tibble(numbers = seq_len(3))\n\ncross_join(some_letters, some_numbers)## # A tibble: 9 × 2\n##   letter numbers\n##   <chr>    <int>\n## 1 A            1\n## 2 A            2\n## 3 A            3\n## 4 B            1\n## 5 B            2\n## 6 B            3\n## 7 C            1\n## 8 C            2\n## 9 C            3## # A tibble: 60 × 3\n##       id word   cond       \n##    <int> <chr>  <chr>      \n##  1     1 red    congruent  \n##  2     1 red    incongruent\n##  3     1 green  congruent  \n##  4     1 green  incongruent\n##  5     1 blue   congruent  \n##  6     1 blue   incongruent\n##  7     1 yellow congruent  \n##  8     1 yellow incongruent\n##  9     1 purple congruent  \n## 10     1 purple incongruent\n## # ℹ 50 more rows"},{"path":"building-blocks-of-simulation.html","id":"inner-join-with-dplyrinner_join","chapter":"1 Building blocks of simulation","heading":"1.1.5.2 Inner join with dplyr::inner_join()","text":"Sometimes need combine information two tables want possible combinations; rather, want keep rows tables match certain 'key' values.example, participants table participant's age. wanted combine information information trials (e.g., order analyze Stroop interference across age), need way get age variable trials. can use inner_join(), specifying key column argument function.","code":"\nparticipants |>\n  inner_join(trials, by = join_by(id))## # A tibble: 60 × 4\n##       id   age word   cond       \n##    <int> <int> <chr>  <chr>      \n##  1     1    27 red    congruent  \n##  2     1    27 red    incongruent\n##  3     1    27 green  congruent  \n##  4     1    27 green  incongruent\n##  5     1    27 blue   congruent  \n##  6     1    27 blue   incongruent\n##  7     1    27 yellow congruent  \n##  8     1    27 yellow incongruent\n##  9     1    27 purple congruent  \n## 10     1    27 purple incongruent\n## # ℹ 50 more rows"},{"path":"building-blocks-of-simulation.html","id":"funcs","chapter":"1 Building blocks of simulation","heading":"1.1.6 Writing custom functions","text":"Monte Carlo simulation, need thing (variations thing) . Inevitably means writing 'function' encapsulates process. next section, learn power simulation workflow, write custom functions simulate data set (generate_data()), analyze data (analyze_data()) extract statistics (extract_stats()).create function, define object using function named function(). sounds confusing , jump right example. Suppose want function adds two numbers together, x, y, returns sum.code trick.Now defined function, can call .defined , works like function R. can use map().part curly brackets defines function body, computation happens. Data within function encapsulated—variables define inside function forgotten wiped memory function runs. convention, results last computation returned calling process.Sometimes useful specify default arguments save user typing. might want make default value y 10.Now omit y set 10.","code":"\nadd_x_to_y <- function(x, y) {\n  x + y\n}\nadd_x_to_y(2, 3)## [1] 5\nmap(1:5, \\(.x) add_x_to_y(.x, 10))## [[1]]\n## [1] 11\n## \n## [[2]]\n## [1] 12\n## \n## [[3]]\n## [1] 13\n## \n## [[4]]\n## [1] 14\n## \n## [[5]]\n## [1] 15\nadd_x_to_y <- function(x, y = 10) {\n  x + y\n}\nadd_x_to_y(15)## [1] 25"},{"path":"building-blocks-of-simulation.html","id":"power-simulation-basic-workflow","chapter":"1 Building blocks of simulation","heading":"1.2 Power simulation: Basic workflow","text":"\nFigure 1.1: basic workflow behind power simulation.\nNow gone programming basics, ready start building script simulate power. keep things simple, simulate power simplest possible situation: one-sample test, point null hypothesis \\(H_0: \\mu = 0\\).Figure 1.1 presents basic workflow.","code":""},{"path":"building-blocks-of-simulation.html","id":"simulating-a-dataset","chapter":"1 Building blocks of simulation","heading":"1.2.1 Simulating a dataset","text":"first thing write (test) function generate_data() takes population parameters sample size info input creates simulated data output using rnorm().TASK: write function generate_data() takes three arguments input: eff (population intercept parameter), nsubj (number subjects), sd (standard deviation, default 1) generates table simulated data using tibble(). resulting table two columns, subj_id dv (dependent variable; .e., result rnorm()).test function, run code see output matches exactly.","code":"\nset.seed(1451)\n\ngenerate_data(5, 10, 2)## # A tibble: 10 × 2\n##    subj_id     dv\n##      <int>  <dbl>\n##  1       1 -0.420\n##  2       2  3.05 \n##  3       3  2.58 \n##  4       4  6.01 \n##  5       5  5.70 \n##  6       6  8.99 \n##  7       7  4.89 \n##  8       8  2.90 \n##  9       9  1.98 \n## 10      10  4.70generate_data <- function(????) {\n  ## TODO: something with tibble()\n}\ngenerate_data <- function(eff, nsubj, sd = 1) {\n  tibble(subj_id = seq_len(nsubj),\n         dv = rnorm(nsubj, mean = eff, sd = sd))\n}"},{"path":"building-blocks-of-simulation.html","id":"analyzing-the-data","chapter":"1 Building blocks of simulation","heading":"1.2.2 Analyzing the data","text":"Unlike conventional statistical techniques (t-test, ANOVA), linear-mixed effects models estimated iteratively may converge, may yield estimates covariance matrices \"singular\" (.e., can expressed lower dimensionality). track statistics singularity / nonconvergence simulations, repeated messages warnings can annoying running, need 'suppress' . Now, simple one-sample power simulation deal , learn, create function randomly throws warnings (20% time) messages (20% time) can learn deal .name function annoy_user() embed analysis function simulation messages get move linear mixed-effects modeling.Now ready write analysis function. include annoy_user() part function.TASK: use starter code develop analysis function one-sample test (hint: t.test()). function return full 'data object' output t-test function.Note dat |> pull(dv) tidyverse way extracting column data frame.","code":"\nannoy_user <- function() {\n  ## randomly throw messages (20%) or warnings (20%) to annoy the user\n  ## like a linear mixed-effects model\n  x <- sample(1:5, 1) # roll a five-sided die...\n  if (x == 1L) {\n    warning(\"Winter is coming.\")\n  } else if (x == 2L) {\n    message(\"Approaching the singularity.\")\n  } # otherwise do nothing\n  invisible(NULL) ## return NULL invisibly\n}\nanalyze_data <- function(dat) {\n  annoy_user()\n  ## TODO add in your analysis here\n}\nset.seed(1451)\n\ngenerate_data(0, 10) |>\n  analyze_data()## \n##  One Sample t-test\n## \n## data:  pull(dat, dv)\n## t = -0.78487, df = 9, p-value = 0.4527\n## alternative hypothesis: true mean is not equal to 0\n## 95 percent confidence interval:\n##  -1.1935688  0.5786762\n## sample estimates:\n##  mean of x \n## -0.3074463\nanalyze_data <- function(dat) {\n  annoy_user()\n  dat |>\n    pull(dv) |>\n    t.test()\n}"},{"path":"building-blocks-of-simulation.html","id":"trapping","chapter":"1 Building blocks of simulation","heading":"1.2.2.1 Handling warnings and messages","text":"OK, run generate_data() |> analyze_data() bunch times, going occasionally give us bothersome warnings messages.two options : can trap want react way occur; , can suppress clutter output model running. Since ways check convergence / singularity fact, opt suppression. Fortunately R functions suppressMessages() suppressWarnings(), wrap around part code generating side effects. , final analysis function follows.try .future reference, cases want trap error/message/warning, use tryCatch() function instead. See https://adv-r.hadley.nz/conditions.html want deep dive topic condition handling.","code":"\nresult <- map(1:20, \\(.x) generate_data(0, 10) |> analyze_data())## Warning in annoy_user(): Winter is coming.## Approaching the singularity.## Warning in annoy_user(): Winter is coming.\n\n## Warning in annoy_user(): Winter is coming.\n\n## Warning in annoy_user(): Winter is coming.\n\n## Warning in annoy_user(): Winter is coming.## Approaching the singularity.\nanalyze_data <- function(dat) {\n  suppressWarnings(\n    suppressMessages({\n      annoy_user()\n    }))\n  \n  dat |>\n    pull(dv) |>\n    t.test()\n}\nresult <- map(1:20, \\(.x) generate_data(0, 10) |> analyze_data())"},{"path":"building-blocks-of-simulation.html","id":"extract","chapter":"1 Building blocks of simulation","heading":"1.2.3 Extracting statistics","text":"output t.test() gives us data object, better extract relevant stats form table. want function takes statistical data object (fitted model object, mobj) return table statistical information. broom::tidy() comes rescue.Unfortunately function work linear mixed-effects models, extract need ways get . just use broom::tidy() now.call tidy() using broom::tidy() load package. Generally just need single package function good idea load , avoid possible namespace clashes.","code":"\nextract_stats <- function(mobj) {\n  mobj |>\n    broom::tidy()\n}"},{"path":"building-blocks-of-simulation.html","id":"wrapping-it-all-in-a-single-function","chapter":"1 Building blocks of simulation","heading":"1.2.4 Wrapping it all in a single function","text":"Now completed three functions shown Figure 1.1, can string together.want many times. way approach create tibble row generated data, model object, statistics single run.code create tibble run_id (identify row) list-column dat, element contains simulated data.TASK: Update code add two additional rows, mobj (list-column) result applying analyze_data() generated dataset, stats (list-column) result applying extract_stats() element mobj.table result look follows.","code":"\ngenerate_data(0, 10) |>\n  analyze_data() |>\n  extract_stats()## # A tibble: 1 × 8\n##   estimate statistic p.value parameter conf.low conf.high method     alternative\n##      <dbl>     <dbl>   <dbl>     <dbl>    <dbl>     <dbl> <chr>      <chr>      \n## 1   -0.360     -1.24   0.246         9    -1.01     0.295 One Sampl… two.sided\nnmc <- 20L # number of Monte Carlo runs\n\nresult <- tibble(run_id = seq_len(nmc),\n                 dat = map(run_id, \\(.x) generate_data(0, 10)))## # A tibble: 20 × 4\n##    run_id dat               mobj    stats           \n##     <int> <list>            <list>  <list>          \n##  1      1 <tibble [10 × 2]> <htest> <tibble [1 × 8]>\n##  2      2 <tibble [10 × 2]> <htest> <tibble [1 × 8]>\n##  3      3 <tibble [10 × 2]> <htest> <tibble [1 × 8]>\n##  4      4 <tibble [10 × 2]> <htest> <tibble [1 × 8]>\n##  5      5 <tibble [10 × 2]> <htest> <tibble [1 × 8]>\n##  6      6 <tibble [10 × 2]> <htest> <tibble [1 × 8]>\n##  7      7 <tibble [10 × 2]> <htest> <tibble [1 × 8]>\n##  8      8 <tibble [10 × 2]> <htest> <tibble [1 × 8]>\n##  9      9 <tibble [10 × 2]> <htest> <tibble [1 × 8]>\n## 10     10 <tibble [10 × 2]> <htest> <tibble [1 × 8]>\n## 11     11 <tibble [10 × 2]> <htest> <tibble [1 × 8]>\n## 12     12 <tibble [10 × 2]> <htest> <tibble [1 × 8]>\n## 13     13 <tibble [10 × 2]> <htest> <tibble [1 × 8]>\n## 14     14 <tibble [10 × 2]> <htest> <tibble [1 × 8]>\n## 15     15 <tibble [10 × 2]> <htest> <tibble [1 × 8]>\n## 16     16 <tibble [10 × 2]> <htest> <tibble [1 × 8]>\n## 17     17 <tibble [10 × 2]> <htest> <tibble [1 × 8]>\n## 18     18 <tibble [10 × 2]> <htest> <tibble [1 × 8]>\n## 19     19 <tibble [10 × 2]> <htest> <tibble [1 × 8]>\n## 20     20 <tibble [10 × 2]> <htest> <tibble [1 × 8]>\nnmc <- 20L # number of Monte Carlo runs\n\nresult <- tibble(run_id = seq_len(nmc),\n                 dat = map(run_id, \\(.x) generate_data(0, 10)),\n                 mobj = map(dat, \\(.x) analyze_data(.x)),\n                 stats = map(mobj, \\(.x) extract_stats(.x)))"},{"path":"building-blocks-of-simulation.html","id":"calculating-power","chapter":"1 Building blocks of simulation","heading":"1.2.4.1 Calculating power","text":"getting close! Now need compute power based statistics calculated (stats) column. can extract using select() unnest() like .Now adapt code function compute_power() takes table x (e.g., result) input along alpha level (defaulting .05) returns power table nsig (number significant runs), N (total runs), power (proportion runs significant).got p.value column unnesting.p.value < alpha compare p value alpha return TRUE statistically significant, false otherwise.something summarize() calculate number runs significant.TASK: wrap code function do_once(), can run batch mode well interactively, goes way generate_data() compute_power(). function accept input arguments nmc (number Monte Carlo runs), eff (effect size), nsubj (number subjects), sd (standard deviation), alpha level alpha (defaulting .05). function return results compute_power().complete, test using code . output identical.OK, one last amendment do_once(). function can take long time return depending number Monte Carlo runs needs complete. useful send message user user knows program just hang. .OK, now got far, take step back celebrate function, do_once(), runs power simulation given population parameters, alpha level, sample size user input.","code":"\nresult |>\n  select(run_id, stats) |>\n  unnest(stats)## # A tibble: 20 × 9\n##    run_id estimate statistic  p.value parameter conf.low conf.high method       \n##     <int>    <dbl>     <dbl>    <dbl>     <dbl>    <dbl>     <dbl> <chr>        \n##  1      1  -0.338     -1.20  0.260            9   -0.974     0.298 One Sample t…\n##  2      2   0.482      1.74  0.115            9   -0.144     1.11  One Sample t…\n##  3      3  -0.258     -1.16  0.274            9   -0.761     0.244 One Sample t…\n##  4      4  -0.113     -0.491 0.635            9   -0.632     0.407 One Sample t…\n##  5      5  -0.447     -1.61  0.143            9   -1.08      0.183 One Sample t…\n##  6      6   0.0683     0.209 0.839            9   -0.669     0.806 One Sample t…\n##  7      7   0.264      0.810 0.439            9   -0.473     1.00  One Sample t…\n##  8      8  -0.622     -1.86  0.0959           9   -1.38      0.135 One Sample t…\n##  9      9  -0.0249    -0.106 0.918            9   -0.555     0.505 One Sample t…\n## 10     10  -0.139     -0.536 0.605            9   -0.728     0.449 One Sample t…\n## 11     11  -0.597     -2.97  0.0157           9   -1.05     -0.143 One Sample t…\n## 12     12   0.172      0.533 0.607            9   -0.556     0.899 One Sample t…\n## 13     13   0.449      1.28  0.232            9   -0.343     1.24  One Sample t…\n## 14     14  -0.218     -1.04  0.324            9   -0.691     0.254 One Sample t…\n## 15     15  -0.478     -1.43  0.187            9   -1.23      0.279 One Sample t…\n## 16     16  -0.305     -0.808 0.440            9   -1.16      0.549 One Sample t…\n## 17     17  -0.627     -1.54  0.158            9   -1.55      0.295 One Sample t…\n## 18     18   0.111      0.390 0.706            9   -0.532     0.753 One Sample t…\n## 19     19  -0.762     -5.60  0.000335         9   -1.07     -0.454 One Sample t…\n## 20     20  -0.122     -0.480 0.642            9   -0.697     0.453 One Sample t…\n## # ℹ 1 more variable: alternative <chr>\ncompute_power <- function(x, alpha = .05) {\n  x |>\n    select(stats) |>\n    unnest(stats) |>\n    summarize(nsig = sum(p.value < alpha),\n              N = n(),\n              power = nsig / N)\n}\nset.seed(1451)\n\ndo_once(nmc = 1000, eff = 0, nsubj = 20, sd = 1, alpha = .05)## # A tibble: 1 × 3\n##    nsig     N power\n##   <int> <int> <dbl>\n## 1    47  1000 0.047\ndo_once <- function(nmc, eff, nsubj, sd, alpha = .05) {\n  tibble(run_id = seq_len(nmc),\n         dat = map(run_id, \\(.x) generate_data(eff, nsubj, sd)),\n         mobj = map(dat, \\(.x) analyze_data(.x)),\n         stats = map(mobj, \\(.x) extract_stats(.x))) |>\n    compute_power(alpha)\n}\ndo_once <- function(nmc, eff, nsubj, sd, alpha = .05) {\n\n  message(\"computing power over \", nmc, \" runs with eff=\",\n          eff, \"; nsubj=\", nsubj, \"; sd = \", sd, \"; alpha = \", alpha)\n  \n  tibble(run_id = seq_len(nmc),\n         dat = map(run_id, \\(.x) generate_data(eff, nsubj, sd)),\n         mobj = map(dat, \\(.x) analyze_data(.x)),\n         stats = map(mobj, \\(.x) extract_stats(.x))) |>\n    compute_power(alpha)\n}"},{"path":"building-blocks-of-simulation.html","id":"calculating-power-curves","chapter":"1 Building blocks of simulation","heading":"1.2.5 Calculating power curves","text":", now calculated power curve single parameter setting. usually want calculate power curve can see power varies function parameter (usually, effect size sample size). can ?Well, given encapulated guts simulation single function, simple matter just calling function repeatedly different inputs storing results. Sound familiar?TASK: Create tibble parameter values eff (effect size) going 5 steps zero 1.5. tibble column pow, results do_once() called value eff (nsubj, sd, nmc held constant 20, 1, 1000 respectively).set seed 1451 run , print , resulting table look like .","code":"## computing power over 1000 runs with eff=0; nsubj=20; sd = 1; alpha = 0.05## computing power over 1000 runs with eff=0.3; nsubj=20; sd = 1; alpha = 0.05## computing power over 1000 runs with eff=0.6; nsubj=20; sd = 1; alpha = 0.05## computing power over 1000 runs with eff=0.9; nsubj=20; sd = 1; alpha = 0.05## computing power over 1000 runs with eff=1.2; nsubj=20; sd = 1; alpha = 0.05## # A tibble: 5 × 4\n##     eff  nsig     N power\n##   <dbl> <int> <int> <dbl>\n## 1   0      47  1000 0.047\n## 2   0.3   262  1000 0.262\n## 3   0.6   719  1000 0.719\n## 4   0.9   976  1000 0.976\n## 5   1.2   999  1000 0.999\nseq(0, 1.2, length.out = 5)pow_result <- tibble(eff = seq(???),\n                     pow = map(eff, ???)) |>\n  unnest(pow)\n\npow_result\npow_result <- tibble(eff = seq(0, 1.2, length.out = 5),\n                     pow = map(eff, \\(.x) do_once(1000, .x, 20, 1))) |>\n  unnest(pow)"},{"path":"building-blocks-of-simulation.html","id":"the-full-script","chapter":"1 Building blocks of simulation","heading":"1.3 The full script","text":"Running power simulations can take long time. surely want save results done, probably make reproducible setting seed calling functions. ! now self-contained, reproducible script calculating power.","code":"\n#############################\n## ADD-ON PACKAGES\n\nsuppressPackageStartupMessages({\n  library(\"dplyr\")  # select(), mutate(), summarize(), inner_join()\n  library(\"tibble\") # tibble() [data entry]\n  library(\"purrr\")  # just for map()\n  library(\"tidyr\")  # nest(), unnest()\n\n  requireNamespace(\"broom\") # don't load, just fail if it's not there\n})\n\n\n#############################\n## MAIN FUNCTIONS\n\ngenerate_data <- function(eff, nsubj, sd = 1) {\n  tibble(subj_id = seq_len(nsubj),\n         dv = rnorm(nsubj, mean = eff, sd = sd))\n}\n\nanalyze_data <- function(dat) {\n  suppressWarnings(\n    suppressMessages({\n      annoy_user()\n    }))\n  \n  dat |>\n    pull(dv) |>\n    t.test()\n}\n\nextract_stats <- function(mobj) {\n  mobj |>\n    broom::tidy()\n}\n\n#############################\n## UTILITY FUNCTIONS\n\nannoy_user <- function() {\n  ## randomly throw messages (20%) or warnings (20%) to annoy the user\n  ## like a linear mixed-effects model\n  x <- sample(1:5, 1) # roll a five-sided die...\n  if (x == 1L) {\n    warning(\"Winter is coming.\")\n  } else if (x == 2L) {\n    message(\"Approaching the singularity.\")\n  } # otherwise do nothing\n  invisible(NULL) ## return NULL invisibly\n}\n\ncompute_power <- function(x, alpha = .05) {\n  x |>\n    select(stats) |>\n    unnest(stats) |>\n    summarize(nsig = sum(p.value < alpha),\n              N = n(),\n              power = nsig / N)\n}\n\ndo_once <- function(nmc, eff, nsubj, sd, alpha = .05) {\n\n  message(\"computing power over \", nmc, \" runs with eff=\",\n          eff, \"; nsubj=\", nsubj, \"; sd = \", sd, \"; alpha = \", alpha)\n  \n  tibble(run_id = seq_len(nmc),\n         dat = map(run_id, \\(.x) generate_data(eff, nsubj, sd)),\n         mobj = map(dat, \\(.x) analyze_data(.x)),\n         stats = map(mobj, \\(.x) extract_stats(.x))) |>\n    compute_power(alpha)\n}\n\n#############################\n## MAIN PROCEDURE\n\n## TODO: possibly set the seed to something for reproducibility?\n\npow_result <- tibble(eff = seq(0, 1.2, length.out = 5),\n                     pow = map(eff, \\(.x) do_once(1000, .x, 20, 1))) |>\n  unnest(pow)\n\npow_result\n\noutfile <- \"simulation-results-one-sample.rds\"\n\nsaveRDS(pow_result, file = outfile)\nmessage(\"saved results to '\", outfile, \"'\")"},{"path":"linear-mixed-effects-modeling.html","id":"linear-mixed-effects-modeling","chapter":"2 Linear mixed-effects modeling","heading":"2 Linear mixed-effects modeling","text":"first section, learn simulate data corresponding experiment single, two-level factor (independent variable) within-subjects -items. imagine experiment involves lexical decisions set words (e.g., \"PINT\" word nonword?), dependent variable response time (milliseconds), independent variable word type (noun vs verb). want treat subjects words random factors (can generalize population events subjects encounter words).general linear model study :\\[Y_{si} = \\beta_0 + S_{0s} + I_{0i} + (\\beta_1 + S_{1s})X_{} + e_{si}\\]:Subjects\\[\\left<S_{0i},S_{1i}\\right> \\sim N(\\left<0,0\\right>, \\Sigma)\\]\\[\\Sigma = \\left(\\begin{array}{cc}{\\tau_{00}}^2 & \\rho\\tau_{00}\\tau_{11} \\\\ \\rho\\tau_{00}\\tau_{11} & {\\tau_{11}}^2 \\\\ \\end{array}\\right) \\]Items\\[I_{0i} \\sim N(0, \\omega_{00}^2)\\]","code":""},{"path":"linear-mixed-effects-modeling.html","id":"generate-data","chapter":"2 Linear mixed-effects modeling","heading":"2.1 Generate data","text":"","code":""},{"path":"linear-mixed-effects-modeling.html","id":"set-up-the-environment","chapter":"2 Linear mixed-effects modeling","heading":"2.1.1 Set up the environment","text":"want get results everyone else exercise, seed random number generator value. , load packages need.","code":"\nlibrary(\"lme4\")\nlibrary(\"tidyverse\")\nrequireNamespace(\"MASS\") ## make sure it's there but don't load it\n\nset.seed(1451)"},{"path":"linear-mixed-effects-modeling.html","id":"dgp","chapter":"2 Linear mixed-effects modeling","heading":"2.1.2 Define the parameters for the DGP","text":"Now define parameters DGP (data generating process).create three tables:merge together information three tables, calculate response variable according model formula .","code":"\nnsubj <- 100 # number of subjects\nnitem <- 50  # must be an even number\n\nmu <- 800 # grand mean\neff <- 80 # 80 ms difference\n\niri_sd <- 80 # by-item random intercept sd (omega_00)\n\n## for the by-subjects variance-covariance matrix\nsri_sd <- 100 # by-subject random intercept sd\nsrs_sd <- 40 # by-subject random slope sd\nrcor <- .2 # correlation between intercept and slope\n\nerr_sd <- 200 # residual (standard deviation)"},{"path":"linear-mixed-effects-modeling.html","id":"generate-a-sample-of-stimuli","chapter":"2 Linear mixed-effects modeling","heading":"2.1.3 Generate a sample of stimuli","text":"randomly generate 50 items. Create tibble called item like one , iri -item random intercepts (drawn normal distribution variance \\(\\omega_{00}^2\\) = iri_sd^2). Half words type NOUN (cond = -.5) half type VERB (cond = .5).rep()rnorm(nitem, ???, ????...)","code":"## # A tibble: 50 × 3\n##    item_id  cond     iri\n##      <int> <dbl>   <dbl>\n##  1       1  -0.5 -217.  \n##  2       2   0.5  -77.9 \n##  3       3  -0.5  -96.9 \n##  4       4   0.5   40.4 \n##  5       5  -0.5   28.0 \n##  6       6   0.5  160.  \n##  7       7  -0.5   -4.45\n##  8       8   0.5  -83.9 \n##  9       9  -0.5 -121.  \n## 10      10   0.5  -12.1 \n## # ℹ 40 more rows\nitems <- tibble(item_id = 1:nitem,\n                cond = rep(c(-.5, .5), times = nitem / 2),\n                iri = rnorm(nitem, 0, sd = iri_sd))"},{"path":"linear-mixed-effects-modeling.html","id":"generate-a-sample-of-subjects","chapter":"2 Linear mixed-effects modeling","heading":"2.1.4 Generate a sample of subjects","text":"generate -subject random effects, need generate data bivariate normal distribution. , use function MASS::mvrnorm().run library(\"MASS\") just get one function, MASS function select() overwrite tidyverse version. Since want MASS mvrnorm() function, can just access directly pkgname::function syntax, .e., MASS::mvrnorm().example use MASS::mvrnorm() randomly generate correlated data (\\(r = -.6\\)) simple bivariate case. example, variances two variables defined 1, covariance becomes equal correlation variables.subjects table look like :recall :as_tibble(mx)","code":"\n## mx is the variance-covariance matrix\nmx <- rbind(c(1, -.6),\n            c(-.6, 1))\n\nbiv_data <- MASS::mvrnorm(1000,\n                          mu = c(V1 = 0, V2 = 0),\n                          Sigma = mx)\n\n## look at biv_data\nggplot(as_tibble(biv_data), aes(V1, V2)) +\n  geom_point()## # A tibble: 100 × 3\n##     subj_id      sri      srs\n##       <int>    <dbl>    <dbl>\n##   1       1   42.9    25.7   \n##   2       2  -15.3   -28.2   \n##   3       3  -41.4   -30.3   \n##   4       4  -77.1     3.64  \n##   5       5  182.      2.48  \n##   6       6   24.6   -13.3   \n##   7       7    8.92   42.8   \n##   8       8 -101.    -37.2   \n##   9       9  -96.8   -32.7   \n##  10      10  -27.4   -52.6   \n##  11      11  -80.8    -9.06  \n##  12      12   83.8   -40.3   \n##  13      13  134.    -18.9   \n##  14      14 -130.    132.    \n##  15      15  -59.2    -8.42  \n##  16      16 -127.     12.5   \n##  17      17    8.91  -15.3   \n##  18      18  -26.8   -19.0   \n##  19      19   48.0    39.5   \n##  20      20   35.6    28.5   \n##  21      21 -199.    -32.9   \n##  22      22  -41.1    -9.77  \n##  23      23  -29.9     1.02  \n##  24      24   12.0   -24.0   \n##  25      25   20.5     0.0251\n##  26      26   -0.207  47.9   \n##  27      27  -13.7   -77.8   \n##  28      28 -154.     31.5   \n##  29      29  -59.6    67.7   \n##  30      30  -50.6   -27.6   \n##  31      31  125.      9.51  \n##  32      32  111.     13.4   \n##  33      33  -27.0    71.7   \n##  34      34 -140.     -7.69  \n##  35      35  -31.0    18.4   \n##  36      36 -185.     31.4   \n##  37      37   12.8   -65.8   \n##  38      38  -39.7   -51.6   \n##  39      39  -93.9    76.3   \n##  40      40  -63.9   -12.5   \n##  41      41   68.6    -3.47  \n##  42      42  -91.9   -31.8   \n##  43      43 -143.     53.9   \n##  44      44   44.6    48.0   \n##  45      45    5.72   24.2   \n##  46      46   51.3   101.    \n##  47      47 -176.    -47.8   \n##  48      48  -54.0   -23.8   \n##  49      49   26.8    32.3   \n##  50      50   20.4    -9.41  \n##  51      51  122.     -2.03  \n##  52      52 -111.    -16.1   \n##  53      53  266.     16.4   \n##  54      54  -42.1    -6.37  \n##  55      55   -3.47  -30.1   \n##  56      56   94.9    18.0   \n##  57      57  -26.9   -19.9   \n##  58      58  154.     43.0   \n##  59      59  110.    -18.9   \n##  60      60 -167.    -14.9   \n##  61      61 -255.     -1.70  \n##  62      62   95.9   -28.8   \n##  63      63  211.    -78.7   \n##  64      64  -40.7   102.    \n##  65      65 -174.     -1.30  \n##  66      66   42.3    11.0   \n##  67      67 -120.    -94.1   \n##  68      68 -173.     10.0   \n##  69      69 -239.     -7.33  \n##  70      70   28.8   -29.9   \n##  71      71  107.     13.1   \n##  72      72 -114.     -3.12  \n##  73      73 -114.     20.7   \n##  74      74  -23.5   -29.4   \n##  75      75  -77.5    23.9   \n##  76      76  160.     78.6   \n##  77      77 -139.     40.6   \n##  78      78   88.2    31.3   \n##  79      79   -2.36  -24.1   \n##  80      80    6.12    6.91  \n##  81      81  -10.8   -47.2   \n##  82      82   97.5    48.6   \n##  83      83   38.4     5.61  \n##  84      84    7.07  -42.2   \n##  85      85   81.2    17.9   \n##  86      86   52.8    80.4   \n##  87      87  -78.4    16.8   \n##  88      88 -116.     36.9   \n##  89      89  -88.6    18.4   \n##  90      90  -36.9   -12.9   \n##  91      91 -100.    -21.8   \n##  92      92 -114.    -18.9   \n##  93      93   25.9   -45.2   \n##  94      94  173.     52.7   \n##  95      95   18.0   -68.1   \n##  96      96 -112.     43.9   \n##  97      97   20.9    -2.86  \n##  98      98  169.     -2.79  \n##  99      99 -101.     -3.88  \n## 100     100  106.    -27.6covariance = r * sri_sd * srs_sd\n## bind together rows\nrbind(\n  c(sri_sd^2,            r * sri_sd * srs_sd),\n  c(r * sri_sd * srs_sd,            srs_sd^2)  )\n\n## see also `matrix()`\nmx <- rbind(c(sri_sd^2,               rcor * sri_sd * srs_sd),\n            c(rcor * sri_sd * srs_sd, srs_sd^2)) # look at it\n\nby_subj_rfx <- MASS::mvrnorm(nsubj,\n                             mu = c(sri = 0, srs = 0),\n                             Sigma = mx)\n\nsubjects <- as_tibble(by_subj_rfx) |>\n  mutate(subj_id = row_number()) |>\n  select(subj_id, everything())"},{"path":"linear-mixed-effects-modeling.html","id":"generate-a-sample-of-encounters-trials","chapter":"2 Linear mixed-effects modeling","heading":"2.1.5 Generate a sample of encounters (trials)","text":"trial encounter particular subject stimulus. experiment, subject see stimulus. Generate table trials lists encounters experiments. Note: participant encounters stimulus item . Use cross_join() function create possible encounters.Now apply example generate table , err residual term, drawn \\(N \\sim \\left(0, \\sigma^2\\right)\\), \\(\\sigma\\) err_sd.","code":"## # A tibble: 5,000 × 3\n##    subj_id item_id    err\n##      <int>   <int>  <dbl>\n##  1       1       1  -64.3\n##  2       1       2  585. \n##  3       1       3  127. \n##  4       1       4  182. \n##  5       1       5  -47.6\n##  6       1       6   22.0\n##  7       1       7 -265. \n##  8       1       8  604. \n##  9       1       9  249. \n## 10       1      10 -147. \n## # ℹ 4,990 more rows\ntrials <- cross_join(subjects |> select(subj_id),\n                     items |> select(item_id)) |>\n  mutate(err = rnorm(n = nsubj * nitem,\n                     mean = 0, sd = err_sd))  "},{"path":"linear-mixed-effects-modeling.html","id":"join-subjects-items-and-trials","chapter":"2 Linear mixed-effects modeling","heading":"2.1.6 Join subjects, items, and trials","text":"Merge information subjects, items, trials create full dataset dat, looks like :Note: full decomposition table model.","code":"## # A tibble: 5,000 × 7\n##    subj_id item_id   sri     iri   srs  cond    err\n##      <int>   <int> <dbl>   <dbl> <dbl> <dbl>  <dbl>\n##  1       1       1  42.9 -217.    25.7  -0.5  -64.3\n##  2       1       2  42.9  -77.9   25.7   0.5  585. \n##  3       1       3  42.9  -96.9   25.7  -0.5  127. \n##  4       1       4  42.9   40.4   25.7   0.5  182. \n##  5       1       5  42.9   28.0   25.7  -0.5  -47.6\n##  6       1       6  42.9  160.    25.7   0.5   22.0\n##  7       1       7  42.9   -4.45  25.7  -0.5 -265. \n##  8       1       8  42.9  -83.9   25.7   0.5  604. \n##  9       1       9  42.9 -121.    25.7  -0.5  249. \n## 10       1      10  42.9  -12.1   25.7   0.5 -147. \n## # ℹ 4,990 more rows\ndat_sim <- subjects |>\n  inner_join(trials, \"subj_id\") |>\n  inner_join(items, \"item_id\") |>\n  arrange(subj_id, item_id) |>\n  select(subj_id, item_id, sri, iri, srs, cond, err)"},{"path":"linear-mixed-effects-modeling.html","id":"addy","chapter":"2 Linear mixed-effects modeling","heading":"2.1.7 Create the response variable","text":"Add response variable Y dat according model formula:\\[Y_{si} = \\beta_0 + S_{0s} + I_{0i} + (\\beta_1 + S_{1s})X_{} + e_{si}\\]resulting table (dat2) looks like :","code":"## # A tibble: 5,000 × 8\n##    subj_id item_id     Y   sri     iri   srs  cond    err\n##      <int>   <int> <dbl> <dbl>   <dbl> <dbl> <dbl>  <dbl>\n##  1       1       1  509.  42.9 -217.    25.7  -0.5  -64.3\n##  2       1       2 1403.  42.9  -77.9   25.7   0.5  585. \n##  3       1       3  820.  42.9  -96.9   25.7  -0.5  127. \n##  4       1       4 1118.  42.9   40.4   25.7   0.5  182. \n##  5       1       5  770.  42.9   28.0   25.7  -0.5  -47.6\n##  6       1       6 1077.  42.9  160.    25.7   0.5   22.0\n##  7       1       7  520.  42.9   -4.45  25.7  -0.5 -265. \n##  8       1       8 1416.  42.9  -83.9   25.7   0.5  604. \n##  9       1       9  918.  42.9 -121.    25.7  -0.5  249. \n## 10       1      10  737.  42.9  -12.1   25.7   0.5 -147. \n## # ℹ 4,990 more rows\ndat_sim2 <- dat_sim |>\n  mutate(Y = mu + sri + iri + (eff + srs) * cond + err) |>\n  select(subj_id, item_id, Y, everything())"},{"path":"linear-mixed-effects-modeling.html","id":"fitting-the-model","chapter":"2 Linear mixed-effects modeling","heading":"2.1.8 Fitting the model","text":"Now created simulated data, estimate model using lme4::lmer(), run summary().Now see can identify data generating parameters output summary().First, try find \\(\\beta_0\\) \\(\\beta_1\\).Now try find estimates random effects parameters \\(\\tau_{00}\\), \\(\\tau_{11}\\), \\(\\rho\\), \\(\\omega_{00}\\), \\(\\sigma\\).","code":"\nmod_sim <- lmer(Y ~ cond + (1 + cond | subj_id) + (1 | item_id),\n                dat_sim2, REML = FALSE)\n\nsummary(mod_sim, corr = FALSE)## Linear mixed model fit by maximum likelihood  ['lmerMod']\n## Formula: Y ~ cond + (1 + cond | subj_id) + (1 | item_id)\n##    Data: dat_sim2\n## \n##      AIC      BIC   logLik deviance df.resid \n##  67657.9  67703.6 -33822.0  67643.9     4993 \n## \n## Scaled residuals: \n##     Min      1Q  Median      3Q     Max \n## -3.7634 -0.6571 -0.0058  0.6572  3.2204 \n## \n## Random effects:\n##  Groups   Name        Variance Std.Dev. Corr\n##  subj_id  (Intercept) 10283.1  101.41       \n##           cond          993.8   31.52   0.13\n##  item_id  (Intercept)  7397.3   86.01       \n##  Residual             40296.4  200.74       \n## Number of obs: 5000, groups:  subj_id, 100; item_id, 50\n## \n## Fixed effects:\n##             Estimate Std. Error t value\n## (Intercept)   784.73      16.09  48.776\n## cond           76.01      25.18   3.019"},{"path":"linear-mixed-effects-modeling.html","id":"building-the-simulation-script","chapter":"2 Linear mixed-effects modeling","heading":"2.2 Building the simulation script","text":"Now learned simulated data crossed random factors subjects stimuli, build script run simulation. might want start fresh R script (load tidyverse + lme4 top).","code":""},{"path":"linear-mixed-effects-modeling.html","id":"wrapping-the-code-into-generate_data","chapter":"2 Linear mixed-effects modeling","heading":"2.2.1 Wrapping the code into generate_data()","text":"Now wrap code created section 2.1.2 2.1.7 single function generate_data() takes arguments: eff (effect size), nsubj (number subjects), nitem (number items), remaining DGP paramemters order: mu, iri_sd, sri_sd, srs_sd, rcor, err_sd.code return table columns subj_id, item_id, cond, Y.'starter' code nothing.","code":"\ngenerate_data <- function(eff, nsubj, nitem,\n                          mu, iri_sd, sri_sd,\n                          srs_sd, rcor, err_sd) {\n\n  ## 1. TODO generate sample of stimuli\n  ## 2. TODO generate sample of subjects\n  ## 3. TODO generate trials, adding in error\n  ## 4. TODO join the three tables together\n  ## 5. TODO create the response variable\n\n  ## TODO replace this placeholder table with your result\n  tibble(subj_id = integer(0),\n         item_id = integer(0),\n         cond = double(0),\n         Y = double(0))\n}\n\n## test it out\ngenerate_data(0, 50, 10,\n              mu = 800, iri_sd = 80, sri_sd = 100,\n              srs_sd = 40, rcor = .2, err_sd = 200)\ngenerate_data <- function(eff, nsubj, nitem,\n                          mu, iri_sd, sri_sd,\n                          srs_sd, rcor, err_sd) {\n\n  ## 1. generate sample of stimuli\n  items <- tibble(item_id = 1:nitem,\n                  cond = rep(c(-.5, .5), times = nitem / 2),\n                  iri = rnorm(nitem, 0, sd = iri_sd))\n  \n  ## 2. generate sample of subjects\n  mx <- rbind(c(sri_sd^2,               rcor * sri_sd * srs_sd),\n              c(rcor * sri_sd * srs_sd, srs_sd^2)) # look at it\n\n  by_subj_rfx <- MASS::mvrnorm(nsubj,\n                               mu = c(sri = 0, srs = 0),\n                               Sigma = mx)\n\n  subjects <- as_tibble(by_subj_rfx) |>\n    mutate(subj_id = row_number()) |>\n    select(subj_id, everything())\n  \n  ## 3. generate trials, adding in error\n  trials <- cross_join(subjects |> select(subj_id),\n                       items |> select(item_id)) |>\n    mutate(err = rnorm(n = nsubj * nitem,\n                       mean = 0, sd = err_sd))\n  \n  ## 4. join the three tables together, AND\n  ## 5. create the response variable\n  subjects |>\n    inner_join(trials, \"subj_id\") |>\n    inner_join(items, \"item_id\") |>\n    mutate(Y = mu + sri + iri + (eff + srs) * cond + err) |>\n    select(subj_id, item_id, cond, Y)\n}"},{"path":"linear-mixed-effects-modeling.html","id":"re-write-analyze_data","chapter":"2 Linear mixed-effects modeling","heading":"2.2.2 Re-write analyze_data()","text":"Now re-write analyze_data() function design.","code":"\nanalyze_data <- function(dat) {\n  suppressWarnings( # ignore non-convergence\n    suppressMessages({ # ignore 'singular fit'\n      ## TODO: something with lmer()\n    }))\n}\nanalyze_data <- function(dat) {\n  suppressWarnings( # ignore non-convergence\n    suppressMessages({ # ignore 'singular fit'\n      lmer(Y ~ cond + (cond | subj_id) +\n             (1 | item_id), data = dat)\n    }))\n}"},{"path":"linear-mixed-effects-modeling.html","id":"re-write-extract_stats","chapter":"2 Linear mixed-effects modeling","heading":"2.2.3 Re-write extract_stats()","text":"Currently, extract_stats() pulls information intercept term.change gets information coefficient cond.function calls check_converged(), need copy session .previous version extract_stats() need change.","code":"\ncheck_converged <- function(mobj) {\n  ## warning: this is kind of a hack!\n  ## see also performance::check_convergence()\n  sm <- summary(mobj)\n  is.null(sm$optinfo$conv$lme4$messages)\n}\nextract_stats <- function(mobj) {\n  tibble(sing = isSingular(mobj),\n         conv = check_converged(mobj),\n         estimate = fixef(mobj)[1],\n         stderr = sqrt(diag(vcov(mobj)))[1],\n         tval = estimate / stderr,\n         pval = 2 * (1 - pnorm(abs(tval))))\n}\nextract_stats <- function(mobj) {\n  tibble(sing = isSingular(mobj),\n         conv = check_converged(mobj),\n         estimate = fixef(mobj)[\"cond\"],\n         stderr = sqrt(diag(vcov(mobj)))[\"cond\"],\n         tval = estimate / stderr,\n         pval = 2 * (1 - pnorm(abs(tval))))\n}"},{"path":"linear-mixed-effects-modeling.html","id":"re-write-do_once","chapter":"2 Linear mixed-effects modeling","heading":"2.2.4 Re-write do_once()","text":"function do_once() performs three functions (generates data, analyzes , subtracts results). needs minor changes work parameters new DGP. also depends upon utility function full_results() can used , repeated can conveniently paste script.Now re-write do_once(). starter code. need change arguments match generate_data() well arguments passed generate_data() via map(). also good idea update message() prints user.","code":"\nfull_results <- function(x, alpha = .05) {\n  ## after completing all the Monte Carlo runs for a set,\n  ## calculate statistics\n  x |>\n    select(run_id, stats) |>\n    unnest(stats) |>\n    summarize(n_sing = sum(sing),\n              n_unconv = sum(!conv),\n              n_sig = sum(pval < alpha),\n              N = n())\n}\ndo_once <- function(eff, nmc, nsubj, ntrials) {\n  ## generate, analyze, and extract for a single parameter setting\n  ## you shouldn't need to change anything about this function except\n  ## the arguments and paramemters passed to generate_data()\n  message(\"computing stats over \", nmc,\n          \" runs for nsubj=\", nsubj, \"; \",\n          \"ntrials=\", ntrials, \"; \",\n          \"eff=\", eff)\n  dat_full <- tibble(run_id = seq_len(nmc)) |>\n    mutate(dat = map(run_id, \\(.x) generate_data(eff, nsubj, ntrials),\n           mobj = map(dat, \\(.x) analyze_data(.x)),\n           stats = map(mobj, \\(.x) extract_stats(.x))))\n  \n  bind_cols(tibble(fdat = list(dat_full)),\n            full_results(dat_full))\n}\ndo_once <- function(eff, nsubj, nitem, nmc,\n                   mu, iri_sd, sri_sd,\n                   srs_sd, rcor, err_sd) {\n  ## generate, analyze, and extract for a single parameter setting\n  message(\"computing stats over \", nmc,\n          \" runs for nsubj=\", nsubj, \"; \",\n          \"nitem=\", nitem, \"; \",\n          \"eff=\", eff)\n  dat_full <- tibble(run_id = seq_len(nmc)) |>\n    mutate(dat = map(run_id, \\(.x) generate_data(eff, nsubj, nitem,\n                                                 mu, iri_sd, sri_sd,\n                                                 srs_sd, rcor, err_sd)),\n           mobj = map(dat, \\(.x) analyze_data(.x)),\n           stats = map(mobj, \\(.x) extract_stats(.x)))\n  \n  bind_cols(tibble(fdat = list(dat_full)),\n            full_results(dat_full))\n}"},{"path":"linear-mixed-effects-modeling.html","id":"main-code","chapter":"2 Linear mixed-effects modeling","heading":"2.2.5 Main code","text":"Now re-written functions, adjust main code template script. really need change code defining allsets calls do_once() new parameter settings. rest can just copy.","code":"\nset.seed(1451) # for deterministic output\n\n## determine effect sizes, nsubj, nitem, and nmc from the command line\nif (length(commandArgs(TRUE)) != 6L) {\n  stop(\"need to specify 'nmc' 'eff_a' 'eff_b' 'steps' 'nsubj' 'nitem'\")\n}\n\nnmc <- commandArgs(TRUE)[1] |> as.integer()   # no. Monte Carlo runs\neff_a <- commandArgs(TRUE)[2] |> as.double()  # smallest effect size\neff_b <- commandArgs(TRUE)[3] |> as.double()  # largest effect size\nsteps <- commandArgs(TRUE)[4] |> as.integer() # number of steps\nnsubj <- commandArgs(TRUE)[5] |> as.integer()\nnitem <- commandArgs(TRUE)[6] |> as.integer()\n\nparams <- tibble(id = seq_len(steps),\n                 eff = seq(eff_a, eff_b, length.out = steps))\n\nallsets <- params |>\n  mutate(result = map(eff,\n                      \\(.x) do_once(.x))) ## add remaining args\n\npow_result <- allsets |>\n  unnest(result) |>\n  mutate(power = n_sig / N) |>\n  select(-fdat)\n\npow_result\n\noutfile <- sprintf(\"sim-results_%d_%0.2f_%0.2f_%d_%d_%d.rds\",\n                   nmc, eff_a, eff_b, steps, nsubj, nitem)\n\nsaveRDS(pow_result, outfile)\n\nmessage(\"results saved to '\", outfile, \"'\")\nset.seed(1451) # for deterministic output\n\n## determine effect sizes, nsubj, nitem, and nmc from the command line\nif (length(commandArgs(TRUE)) != 6L) {\n  stop(\"need to specify 'nmc' 'eff_a' 'eff_b' 'steps' 'nsubj' 'nitem'\")\n}\n\nnmc <- commandArgs(TRUE)[1] |> as.integer()   # no. Monte Carlo runs\neff_a <- commandArgs(TRUE)[2] |> as.double()  # smallest effect size\neff_b <- commandArgs(TRUE)[3] |> as.double()  # largest effect size\nsteps <- commandArgs(TRUE)[4] |> as.integer() # number of steps\nnsubj <- commandArgs(TRUE)[5] |> as.integer()\nnitem <- commandArgs(TRUE)[6] |> as.integer()\n\nparams <- tibble(id = seq_len(steps),\n                 eff = seq(eff_a, eff_b, length.out = steps))\n\nallsets <- params |>\n  mutate(result = map(eff,\n                      \\(.x) do_once(.x, nsubj = nsubj, nitem = nitem, nmc = nmc,\n                                    mu = 800, iri_sd = 80, sri_sd = 100,\n                                    srs_sd = 40, rcor = .2, err_sd = 200)))\n                      \npow_result <- allsets |>\n  unnest(result) |>\n  mutate(power = n_sig / N) |>\n  select(-fdat)\n\npow_result\n\noutfile <- sprintf(\"sim-results_%d_%0.2f_%0.2f_%d_%d_%d.rds\",\n                   nmc, eff_a, eff_b, steps, nsubj, nitem)\n\nsaveRDS(pow_result, outfile)\n\nmessage(\"results saved to '\", outfile, \"'\")"},{"path":"linear-mixed-effects-modeling.html","id":"the-full-script-1","chapter":"2 Linear mixed-effects modeling","heading":"2.2.6 The full script","text":"","code":"\n#############################\n## ADD-ON PACKAGES\n\nsuppressPackageStartupMessages({\n  library(\"dplyr\")\n  library(\"tibble\")\n  library(\"purrr\")\n  library(\"tidyr\")\n\n  library(\"lme4\")\n})\n\nrequireNamespace(\"MASS\") # make sure it's there but don't load it\n\n#############################\n## CUSTOM FUNCTIONS\n\ngenerate_data <- function(eff, nsubj, nitem,\n                          mu, iri_sd, sri_sd,\n                          srs_sd, rcor, err_sd) {\n\n  ## 1. generate sample of stimuli\n  items <- tibble(item_id = 1:nitem,\n                  cond = rep(c(-.5, .5), times = nitem / 2),\n                  iri = rnorm(nitem, 0, sd = iri_sd))\n  \n  ## 2. generate sample of subjects\n  mx <- rbind(c(sri_sd^2,               rcor * sri_sd * srs_sd),\n              c(rcor * sri_sd * srs_sd, srs_sd^2)) # look at it\n\n  by_subj_rfx <- MASS::mvrnorm(nsubj,\n                               mu = c(sri = 0, srs = 0),\n                               Sigma = mx)\n\n  subjects <- as_tibble(by_subj_rfx) |>\n    mutate(subj_id = row_number()) |>\n    select(subj_id, everything())\n  \n  ## 3. generate trials, adding in error\n  trials <- cross_join(subjects |> select(subj_id),\n                       items |> select(item_id)) |>\n    mutate(err = rnorm(n = nsubj * nitem,\n                       mean = 0, sd = err_sd))\n  \n  ## 4. join the three tables together, AND\n  ## 5. create the response variable\n  subjects |>\n    inner_join(trials, \"subj_id\") |>\n    inner_join(items, \"item_id\") |>\n    mutate(Y = mu + sri + iri + (eff + srs) * cond + err) |>\n    select(subj_id, item_id, cond, Y)\n}\n\nanalyze_data <- function(dat) {\n  suppressWarnings( # ignore non-convergence\n    suppressMessages({ # ignore 'singular fit'\n      lmer(Y ~ cond + (cond | subj_id) +\n             (1 | item_id), data = dat)\n    }))\n}\n\nextract_stats <- function(mobj) {\n  tibble(sing = isSingular(mobj),\n         conv = check_converged(mobj),\n         estimate = fixef(mobj)[\"cond\"],\n         stderr = sqrt(diag(vcov(mobj)))[\"cond\"],\n         tval = estimate / stderr,\n         pval = 2 * (1 - pnorm(abs(tval))))\n}\n\n#############################\n## UTILITY FUNCTIONS\n\ncheck_converged <- function(mobj) {\n  ## warning: this is kind of a hack!\n  ## see also performance::check_convergence()\n  sm <- summary(mobj)\n  is.null(sm$optinfo$conv$lme4$messages)\n}\n\nfull_results <- function(x, alpha = .05) {\n  ## after completing all the Monte Carlo runs for a set,\n  ## calculate statistics\n  x |>\n    select(run_id, stats) |>\n    unnest(stats) |>\n    summarize(n_sing = sum(sing),\n              n_unconv = sum(!conv),\n              n_sig = sum(pval < alpha),\n              N = n())\n}\n\ndo_once <- function(eff, nsubj, nitem, nmc,\n                   mu, iri_sd, sri_sd,\n                   srs_sd, rcor, err_sd) {\n  ## generate, analyze, and extract for a single parameter setting\n  message(\"computing stats over \", nmc,\n          \" runs for nsubj=\", nsubj, \"; \",\n          \"nitem=\", nitem, \"; \",\n          \"eff=\", eff)\n  dat_full <- tibble(run_id = seq_len(nmc)) |>\n    mutate(dat = map(run_id, \\(.x) generate_data(eff, nsubj, nitem,\n                                                 mu, iri_sd, sri_sd,\n                                                 srs_sd, rcor, err_sd)),\n           mobj = map(dat, \\(.x) analyze_data(.x)),\n           stats = map(mobj, \\(.x) extract_stats(.x)))\n  \n  bind_cols(tibble(fdat = list(dat_full)),\n            full_results(dat_full))\n}\n\n#############################\n## MAIN CODE STARTS HERE\n\nset.seed(1451) # for deterministic output\n\n## determine effect sizes, nsubj, nitem, and nmc from the command line\nif (length(commandArgs(TRUE)) != 6L) {\n  stop(\"need to specify 'nmc' 'eff_a' 'eff_b' 'steps' 'nsubj' 'nitem'\")\n}\n\nnmc <- commandArgs(TRUE)[1] |> as.integer()   # no. Monte Carlo runs\neff_a <- commandArgs(TRUE)[2] |> as.double()  # smallest effect size\neff_b <- commandArgs(TRUE)[3] |> as.double()  # largest effect size\nsteps <- commandArgs(TRUE)[4] |> as.integer() # number of steps\nnsubj <- commandArgs(TRUE)[5] |> as.integer()\nnitem <- commandArgs(TRUE)[6] |> as.integer()\n\nparams <- tibble(id = seq_len(steps),\n                 eff = seq(eff_a, eff_b, length.out = steps))\n\nallsets <- params |>\n  mutate(result = map(eff,\n                      \\(.x) do_once(.x, nsubj = nsubj, nitem = nitem, nmc = nmc,\n                                    mu = 800, iri_sd = 80, sri_sd = 100,\n                                    srs_sd = 40, rcor = .2, err_sd = 200)))\n                      \npow_result <- allsets |>\n  unnest(result) |>\n  mutate(power = n_sig / N) |>\n  select(-fdat)\n\npow_result\n\noutfile <- sprintf(\"sim-results_%d_%0.2f_%0.2f_%d_%d_%d.rds\",\n                   nmc, eff_a, eff_b, steps, nsubj, nitem)\n\nsaveRDS(pow_result, outfile)\n\nmessage(\"results saved to '\", outfile, \"'\")"},{"path":"references-and-further-reading.html","id":"references-and-further-reading","chapter":"3 References and Further Reading","heading":"3 References and Further Reading","text":"","code":""},{"path":"references-and-further-reading.html","id":"further-reading","chapter":"3 References and Further Reading","heading":"3.1 Further reading","text":"justify sample size (Lakens, 2022).justify sample size (Lakens, 2022).tutorial Lisa DeBruine (DeBruine & Barr, 2021) covers much ground, mainly focused understanding LMEMs workMy tutorial Lisa DeBruine (DeBruine & Barr, 2021) covers much ground, mainly focused understanding LMEMs workOther articles power LMEMs: (Brysbaert & Stevens, 2018), (Kumle et al., 2021), (Westfall et al., 2014)articles power LMEMs: (Brysbaert & Stevens, 2018), (Kumle et al., 2021), (Westfall et al., 2014)Monte Carlo simulations comparing methods getting \\(p\\)-values: (Luke, 2017)Monte Carlo simulations comparing methods getting \\(p\\)-values: (Luke, 2017)Check online textbooks resources group University Glasgow developing. great resources learn data wrangling visualization, among things.","code":""},{"path":"references-and-further-reading.html","id":"r-packages","chapter":"3 References and Further Reading","heading":"3.2 R packages","text":"simr package (Green & MacLeod, 2016){faux} package factorial simulation","code":""},{"path":"references-and-further-reading.html","id":"references","chapter":"3 References and Further Reading","heading":"3.3 References","text":"Brysbaert, M., & Stevens, M. (2018). Power analysis effect size mixed effects models: tutorial. Journal Cognition, 1(1).DeBruine, L. M., & Barr, D. J. (2021). Understanding mixed-effects models data simulation. Advances Methods Practices Psychological Science, 4(1), 2515245920965119.Green, P., & MacLeod, C. J. (2016). SIMR: R package power analysis generalized linear mixed models simulation. Methods Ecology Evolution, 7(4), 493–498.Kumle, L., Võ, M. L.-H., & Draschkow, D. (2021). Estimating power (generalized) linear mixed models: open introduction tutorial R. Behavior Research Methods, 53(6), 2528–2543.Lakens, D. (2022). Sample size justification. Collabra: Psychology, 8(1), 33267. https://doi.org/https://doi.org/10.1525/collabra.33267Luke, S. G. (2017). Evaluating significance linear mixed-effects models R. Behavior Research Methods, 49, 1494–1502.Westfall, J., Kenny, D. ., & Judd, C. M. (2014). Statistical power optimal design experiments samples participants respond samples stimuli. Journal Experimental Psychology: General, 143(5), 2020.","code":""}]
